{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------+---+-------+-------+---+------+\n",
      "|                 _c0|                 _c1|                 _c2|     _c3|_c4|    _c5|    _c6|_c7|   _c8|\n",
      "+--------------------+--------------------+--------------------+--------+---+-------+-------+---+------+\n",
      "|eefc2eb34a354ab7a...|2019-09-12T00:00:...|http://example.co...|user-041| CR|     IE|Android|201|0.2856|\n",
      "|9ba55c683ddd4a05a...|2019-09-12T00:00:...|http://example.co...|user-043| NE| Safari|windows|403|0.2843|\n",
      "|a45df30287454e598...|2019-09-12T00:01:...|http://example.co...|user-005| VI|   Edge|Android|444|0.6983|\n",
      "|941c2d880242431c9...|2019-09-12T00:01:...|http://example.co...|user-092| IS|Firefox|windows|226|0.2636|\n",
      "|97723d7e1669450eb...|2019-09-12T00:02:...|http://example.co...|user-024| GM|Firefox|windows|303|0.0459|\n",
      "+--------------------+--------------------+--------------------+--------+---+-------+-------+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Query3-SQL').getOrCreate()\n",
    "df = spark.read.load(\"hw5_problem2.parquet\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"allData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+\n",
      "|       day|                 url|           avg_ttfb|\n",
      "+----------+--------------------+-------------------+\n",
      "|2019-09-12|http://example.co...| 0.3931014084507042|\n",
      "|2019-09-12|http://example.co...|           0.402545|\n",
      "|2019-09-12|http://example.co...|0.41331718750000007|\n",
      "|2019-09-12|http://example.co...| 0.4188678571428572|\n",
      "|2019-09-12|http://example.co...|0.41928939393939396|\n",
      "|2019-09-12|http://example.co...|0.42255818181818183|\n",
      "|2019-09-12|http://example.co...|  0.428484126984127|\n",
      "|2019-09-12|http://example.co...| 0.4292042857142857|\n",
      "|2019-09-12|http://example.co...| 0.4307040816326531|\n",
      "|2019-09-12|http://example.co...| 0.4317596774193549|\n",
      "+----------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avgTtfbDF = spark.sql(\"\"\"\n",
    "WITH cte AS\n",
    "    ( SELECT SUBSTRING(_c1,1,10) AS day, _c2 AS url, _c8 AS ttfb \n",
    "    FROM allData )\n",
    "SELECT day,url,AVG(ttfb) as avg_ttfb FROM cte\n",
    "GROUP BY day,url\n",
    "ORDER BY day,avg_ttfb,url\n",
    "\"\"\")\n",
    "avgTtfbDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "avgTtfbDF.createOrReplaceTempView(\"avgData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+\n",
      "|       day|                 url|           avg_ttfb|\n",
      "+----------+--------------------+-------------------+\n",
      "|2019-09-12|http://example.co...| 0.3931014084507042|\n",
      "|2019-09-12|http://example.co...|           0.402545|\n",
      "|2019-09-12|http://example.co...|0.41331718750000007|\n",
      "|2019-09-12|http://example.co...| 0.4188678571428572|\n",
      "|2019-09-12|http://example.co...|0.41928939393939396|\n",
      "|2019-09-13|http://example.co...|0.40281428571428574|\n",
      "|2019-09-13|http://example.co...| 0.4294693548387097|\n",
      "|2019-09-13|http://example.co...| 0.4306358490566038|\n",
      "|2019-09-13|http://example.co...| 0.4313811594202898|\n",
      "|2019-09-13|http://example.co...| 0.4319064516129032|\n",
      "|2019-09-14|http://example.co...|0.40559807692307687|\n",
      "|2019-09-14|http://example.co...| 0.4185893333333333|\n",
      "|2019-09-14|http://example.co...|0.42331587301587303|\n",
      "|2019-09-14|http://example.co...| 0.4265705882352941|\n",
      "|2019-09-14|http://example.co...|0.42943692307692305|\n",
      "|2019-09-15|http://example.co...|             0.2863|\n",
      "|2019-09-15|http://example.co...|             0.6621|\n",
      "|2019-09-15|http://example.co...|             0.7849|\n",
      "|2019-09-15|http://example.co...|             0.8516|\n",
      "+----------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH cte AS\n",
    "  ( SELECT day, url, avg_ttfb,\n",
    "           ROW_NUMBER() OVER (PARTITION BY day ORDER BY avg_ttfb ASC) AS ttfb_rank\n",
    "    FROM avgData )\n",
    "SELECT day, url, avg_ttfb FROM cte\n",
    "WHERE ttfb_rank <= 5\n",
    "ORDER BY day,avg_ttfb\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "ttfbDF.createOrReplaceTempView(\"ttfbData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+\n",
      "|       day|                 url|           avg_ttfb|\n",
      "+----------+--------------------+-------------------+\n",
      "|2019-09-12|http://example.co...|0.47357419354838715|\n",
      "|2019-09-12|http://example.co...| 0.4880267605633803|\n",
      "|2019-09-12|http://example.co...| 0.4464488888888889|\n",
      "|2019-09-12|http://example.co...| 0.4611421874999999|\n",
      "|2019-09-12|http://example.co...| 0.5223234567901235|\n",
      "|2019-09-12|http://example.co...| 0.5320376623376624|\n",
      "|2019-09-12|http://example.co...| 0.5226535714285714|\n",
      "|2019-09-12|http://example.co...|0.45305135135135133|\n",
      "|2019-09-12|http://example.co...| 0.4934733333333334|\n",
      "|2019-09-12|http://example.co...| 0.5582210526315791|\n",
      "+----------+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avgTtfbDF = spark.sql(\"\"\"\n",
    "SELECT day,url,AVG(ttfb) as avg_ttfb FROM ttfbData\n",
    "GROUP BY day,url\n",
    "ORDER BY day,url,avg_ttfb\n",
    "\"\"\")\n",
    "avgTtfbDF.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "avgTtfbDF.createOrReplaceTempView(\"avgData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+\n",
      "|       day|                 url|          avg_ttfb|\n",
      "+----------+--------------------+------------------+\n",
      "|2019-09-12|http://example.co...|0.5582210526315791|\n",
      "|2019-09-12|http://example.co...|0.5655351851851852|\n",
      "|2019-09-12|http://example.co...|0.5661685185185186|\n",
      "|2019-09-12|http://example.co...|          0.578595|\n",
      "|2019-09-12|http://example.co...| 0.600576923076923|\n",
      "|2019-09-13|http://example.co...|0.5711131147540983|\n",
      "|2019-09-13|http://example.co...|            0.5753|\n",
      "|2019-09-13|http://example.co...|0.5777212121212122|\n",
      "|2019-09-13|http://example.co...|0.5834452054794521|\n",
      "|2019-09-13|http://example.co...|0.5982431034482759|\n",
      "|2019-09-14|http://example.co...|0.5734783783783786|\n",
      "|2019-09-14|http://example.co...|0.5754071428571429|\n",
      "|2019-09-14|http://example.co...|0.5754943661971831|\n",
      "|2019-09-14|http://example.co...|0.5772901408450704|\n",
      "|2019-09-14|http://example.co...|0.5933677966101695|\n",
      "|2019-09-15|http://example.co...|            0.2863|\n",
      "|2019-09-15|http://example.co...|            0.6621|\n",
      "|2019-09-15|http://example.co...|            0.7849|\n",
      "|2019-09-15|http://example.co...|            0.8516|\n",
      "+----------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "WITH cte AS\n",
    "  ( SELECT day, url, avg_ttfb,\n",
    "           ROW_NUMBER() OVER (PARTITION BY day ORDER BY avg_ttfb DESC) AS ttfb_rank\n",
    "    FROM avgData\n",
    "  )\n",
    "SELECT day, url, avg_ttfb FROM cte\n",
    "WHERE ttfb_rank <= 5\n",
    "ORDER BY day,avg_ttfb\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------------------+---------+\n",
      "|       day|                 url|          avg_ttfb|ttfb_rank|\n",
      "+----------+--------------------+------------------+---------+\n",
      "|2019-09-13|http://example.co...|0.5982431034482759|        1|\n",
      "|2019-09-13|http://example.co...|0.5834452054794521|        2|\n",
      "|2019-09-13|http://example.co...|0.5777212121212122|        3|\n",
      "|2019-09-13|http://example.co...|            0.5753|        4|\n",
      "|2019-09-13|http://example.co...|0.5711131147540983|        5|\n",
      "|2019-09-13|http://example.co...|0.5615442307692308|        6|\n",
      "|2019-09-13|http://example.co...|0.5552396825396826|        7|\n",
      "|2019-09-13|http://example.co...|0.5543915662650603|        8|\n",
      "|2019-09-13|http://example.co...|0.5535523076923078|        9|\n",
      "|2019-09-13|http://example.co...|0.5522982456140351|       10|\n",
      "|2019-09-13|http://example.co...|0.5520215189873419|       11|\n",
      "|2019-09-13|http://example.co...|0.5484666666666667|       12|\n",
      "|2019-09-13|http://example.co...|0.5481449275362319|       13|\n",
      "|2019-09-13|http://example.co...|0.5469184615384615|       14|\n",
      "|2019-09-13|http://example.co...|0.5467129870129871|       15|\n",
      "|2019-09-13|http://example.co...| 0.546308064516129|       16|\n",
      "|2019-09-13|http://example.co...| 0.544512676056338|       17|\n",
      "|2019-09-13|http://example.co...|0.5441210526315791|       18|\n",
      "|2019-09-13|http://example.co...|0.5425292682926829|       19|\n",
      "|2019-09-13|http://example.co...|0.5418657534246576|       20|\n",
      "+----------+--------------------+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT day, url, avg_ttfb, ROW_NUMBER() OVER (PARTITION BY day ORDER BY avg_ttfb DESC) AS ttfb_rank\n",
    "FROM rankedData\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
